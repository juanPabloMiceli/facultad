{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos y graficos usados para el tp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: no se puede crear el directorio «build»: El archivo ya existe\n",
      "/bin/bash: cmake: orden no encontrada\n",
      "[ 50%] Built target metnum\n",
      "[100%] Built target tp2\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Debug\"\n",
      "-- Up-to-date: /home/mariana/Facultad/Metodos/TP2/tp2_metodos/notebooks/metnum.cpython-36m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build/ && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../cmake-build-debug/ && make install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos todo lo que haga falta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mariana/Facultad/Metodos/TP2/tp2_metodos/notebooks\n",
      "Python 3.6.9\n"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalación. Si no falla el import está OK\n",
    "!pwd\n",
    "!python --version\n",
    "import metnum\n",
    "\n",
    "from sklearn.metrics import average_precision_score, accuracy_score, f1_score, precision_score,recall_score, jaccard_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levantamos los archivos de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Shape train: (42000, 785), Shape test: (28000, 784)\n",
      "Ahora tengo 33600 instancias de entrenamiento y 8400 de validación\n",
      "Shape train_8000: (8000, 784)\n",
      "Shape labels_8000: (8000, 1)\n",
      "Shape val_2000: (2000, 784)\n",
      "Shape labels_2000: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_test = pd.read_csv(\"../data/test.csv\")\n",
    "print(f\"Shape train: {df_train.shape}, Shape test: {df_test.shape}\")\n",
    "#df_train=df_train[:10000]\n",
    "\n",
    "# Uso values para mandar todo a arrays de numpy\n",
    "X_train = df_train[df_train.columns[1:]].values\n",
    "y_train = df_train[\"label\"].values.reshape(-1, 1)\n",
    "# X_test=df_test.values\n",
    "# y_test= df_labels_test[\"Label\"].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "limit = int(0.8 * X_train.shape[0]) \n",
    "\n",
    "X_tr, y_tr = X_train[:limit], y_train[:limit]\n",
    "X_val, y_val = X_train[limit:], y_train[limit:]\n",
    "\n",
    "assert len(X_tr) == len(y_tr)\n",
    "assert len(X_val) == len(y_val)\n",
    "\n",
    "print(f\"Ahora tengo {len(X_tr)} instancias de entrenamiento y {len(X_val)} de validación\")\n",
    "\n",
    "\n",
    "train_8000  = (df_train.values)[:8000,1:].reshape(8000,-1)\n",
    "val_2000    = (df_train.values)[8000:10000,1:].reshape(2000,-1)\n",
    "labels_2000 = (df_train.values)[8000:10000,0].reshape(2000, 1)\n",
    "labels_8000 = (df_train.values)[:8000,0].reshape(8000, 1)\n",
    "print(f\"Shape train_8000: {train_8000.shape}\")\n",
    "print(f\"Shape labels_8000: {labels_8000.shape}\")\n",
    "print(f\"Shape val_2000: {val_2000.shape}\")\n",
    "print(f\"Shape labels_2000: {labels_2000.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf=metnum.KNNClassifier(3)\n",
    "pca=metnum.PCA(19)\n",
    "pca.fit(X_tr)\n",
    "X_tr_PCA=pca.transform(X_tr)\n",
    "X_val_PCA=pca.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf.fit(X_tr_PCA, y_tr)\n",
    "Y_pred_PCA=clf.predict(X_val_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculamos la cantidad de imágenes por clase y graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores=[4132,4684,4177, 4351,4072,3795,4137, 4401,4063,4188] #Cantidad de datos de las clases ordenadas.\n",
    "clases=np.arange(10)                                          \n",
    "\n",
    "prom=np.array(valores).mean()                                 #Calculamos el promedio de elementos por clase.\n",
    "promedios=[]\n",
    "for i in range(10):                                           #Ponemos el promedio en un array de 10 posiciones.\n",
    "    promedios.append(prom)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "plt.xticks(clases, clases)\n",
    "plt.xticks(size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.bar(x=clases, height=valores, color=colores)\n",
    "plt.title('Cantidad de elementos por clase', fontsize=16)\n",
    "for i in range(len(valores)):\n",
    "    plt.text(x = clases[i]-0.3 , y = valores[i]+0.01, s = str(valores[i]), size = 12)    #Agregamos los valores sobre las barras\n",
    "plt.xlabel('Cantidad de imágenes', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.ylim(0,5000)\n",
    "plt.plot(clases,promedios, label='Promedio', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo del accuracy de KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def acc_KNN(x_training, y_training, x_val, y_valid, k):\n",
    "    clf = metnum.KNNClassifier(k)\n",
    "    clf.fit(x_training, y_training)\n",
    "    predicciones=clf.predict(x_val)\n",
    "    return accuracy_score(y_valid, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo del accuracy de KNN con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def acc_KNN_PCA(x_training, y_training, x_val, y_valid, k, alfa):\n",
    "    clf = metnum.KNNClassifier(k)\n",
    "    pca=metnum.PCA(alfa)\n",
    "    pca.fit(x_training)\n",
    "    x_tr_pca=pca.transform(x_training)\n",
    "    x_val_pca=pca.transform(x_val)\n",
    "    \n",
    "    clf.fit(x_tr_pca, y_training)\n",
    "    predicciones=clf.predict(x_val_pca)\n",
    "    return accuracy_score(y_valid, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de la accuracy para distintos valores de k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def plotear_todos_k(save=False):\n",
    "    df_all_neighbors = pd.read_csv(\"../data_mediciones/all_predictions.csv\") #Leemos el csv que tiene las predicciones para cada k\n",
    "    all_neighbors_array = (df_all_neighbors.values)[:,1:].astype('int')\n",
    "    accuracy = [0]\n",
    "    for i in range(0, all_neighbors_array.shape[1]):\n",
    "        accuracy.append(accuracy_score(all_neighbors_array[:,i], labels_2000))\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(22,14), dpi=150)\n",
    "    plt.plot(np.arange(0, 8001), np.array(accuracy), label='Accuracy')\n",
    "    plt.xscale('log')\n",
    "    plt.title(\"Accuracy por k con 8000 imagenes\", fontsize=24)\n",
    "    plt.xlabel('k', fontsize=22)\n",
    "    plt.ylabel('Accuracy', fontsize=22)\n",
    "    plt.xlim(1, 8000)\n",
    "    ax.grid(axis='x', which='both')\n",
    "    ax.tick_params(which='minor', length=6, width=2)\n",
    "    plt.legend(loc=\"upper right\", fontsize=19)\n",
    "    ax.tick_params(labelsize=19)\n",
    "    \n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_major_formatter(ScalarFormatter())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('../imagenes_informe/accuracy_por_k_8000_imagenes.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico del tiempo de ejecución de KNN versus k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def plotear_ks_vs_tiempo(ks, tiempos, save=False):\n",
    "    df_ks = pd.read_csv('../data_mediciones/analisis_temporal_ks.csv')\n",
    "    ks = np.arange(1, 101).tolist()\n",
    "    acc_ks = df_ks['accuracy'].values\n",
    "    time_ks = df_ks['time'].values\n",
    "    ks = np.arange(1, 101).tolist()\n",
    "    acc_ks, times_ks = acc_x_k(ks, train_8000, labels_8000, val_2000, labels_2000)\n",
    "    dic_ks = {'accuracy': np.array(acc_ks),\n",
    "               'time':    np.array(times_ks)\n",
    "             }\n",
    "    df_ks = pd.DataFrame(dic_ks)\n",
    "    df_ks.to_csv('../data_mediciones/analisis_temporal_ks.csv')\n",
    "    df_ks = pd.read_csv('../data_mediciones/analisis_temporal_ks.csv')\n",
    "    ks = np.arange(1, 101).tolist()\n",
    "    acc_ks = df_ks['accuracy'].values\n",
    "    time_ks = df_ks['time'].values\n",
    "    \n",
    "    TITLE_SIZE = 24\n",
    "    TICK_SIZE = 22\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(22,14), dpi=150)\n",
    "    plt.plot(np.array(ks), tiempos, color='orange', label='Tiempo')\n",
    "    \n",
    "    m, b = np.polyfit(np.array(ks), np.array(tiempos), 1)\n",
    "    plt.plot(np.array(ks), m*np.array(ks) + b, 'b--', label='Aproximación lineal')\n",
    "\n",
    "\n",
    "    plt.title(\"Tiempo en entrenar y clasificar para distintos ks\", fontsize=24)\n",
    "    plt.xlabel('k', fontsize=TITLE_SIZE)\n",
    "    plt.ylabel('Tiempo de ejecución en segundos', fontsize=TITLE_SIZE)\n",
    "    ax.grid(axis='x', which='both')\n",
    "    \n",
    "\n",
    "    ticks = np.append([1], np.arange(0,101,10)[1:])    \n",
    "    plt.xticks(ticks)\n",
    "    plt.legend(loc=\"best\", fontsize=TITLE_SIZE)\n",
    "    ax.tick_params(labelsize=TICK_SIZE)\n",
    "    \n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_major_formatter(ScalarFormatter())\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('../ks_vs_tiempo_8000_imagenes_line_predict.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploteo de el accuracy para KNN utilizando datasets de distintos tamaños"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos las accuracy's por cada dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def acc_por_n_im(cant_datos, k):                 #Recibe un array con los tamaños de datasets a clasificar\n",
    "    acc=[]\n",
    "    tiempos = []\n",
    "    df_train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "    for i in tqdm(cant_datos):\n",
    "\n",
    "        df_train=df_train[:i]\n",
    "\n",
    "        X = df_train[df_train.columns[1:]].values\n",
    "        y = df_train[\"label\"].values.reshape(-1, 1)\n",
    "\n",
    "\n",
    "        limit = int(0.8 * X.shape[0]) \n",
    "        X_train, y_train = X[:limit], y[:limit]\n",
    "        X_val, y_val = X[limit:], y[limit:]\n",
    "\n",
    "        start = time.time()\n",
    "        acc.append(acc_KNN(X_train, y_train, X_val, y_val,k))\n",
    "        end =  time.time()\n",
    "\n",
    "        tiempos.append(end-start)\n",
    "    return acc, tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "colores=['#2EFE9A', '#BE81F7','#58FAD0']\n",
    "def plotear_acc_dif_im(eje_x, eje_y, k_usado):\n",
    "    x=np.arange(len(eje_x))\n",
    "    fig,ax=plt.subplots(figsize=(10,10))\n",
    "    plt.xticks(x,eje_x)\n",
    "    plt.xticks(size=12)\n",
    "    plt.yticks(size=12)\n",
    "    plt.bar(x=x, height=eje_y, color=colores)\n",
    "    plt.title('Accuracy KNN por cantidad de imágenes con k = {}'.format(k_usado), fontsize=16)\n",
    "    for i in range(len(eje_y)):\n",
    "        plt.text(x = x[i]-0.3 , y = eje_y[i]+0.01, s = str(eje_y[i]), size = 12)\n",
    "    plt.xlabel('Cantidad de imágenes', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploteo de accuracy para distintos valores de k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def plotear_acc_por_k(eje_x, eje_y):\n",
    "    x=np.arange(len(eje_x))\n",
    "    fig,ax=plt.subplots(figsize=(10,10))\n",
    "    plt.xticks(x,eje_x)\n",
    "    plt.xticks(size=16)\n",
    "    plt.yticks(size=16)\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.bar(x=x, height=eje_y, color=colores)\n",
    "    plt.title('Accuracy variando k', fontsize=20)\n",
    "    for i in range(len(eje_y)):\n",
    "        plt.text(x = x[i]-0.3 , y = eje_y[i]+0.01, s = str(eje_y[i]), size = 16)\n",
    "    plt.xlabel('K', fontsize=20)\n",
    "    plt.ylabel('Accuracy', fontsize=20)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploteo del porcentaje de varianza aportado por primeras componentes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def plotear_aporte_autovalores(autovalores, save=False):\n",
    "    sumas_parciales = np.zeros(autovalores.shape[0])\n",
    "    sumas_parciales[0] = autovalores[0]\n",
    "    for i in range(1, sumas_parciales.shape[0]):\n",
    "        sumas_parciales[i] = sumas_parciales[i-1] + autovalores[i]\n",
    "    aportes = [100*(elem/sp)[0] for elem, sp in zip(autovalores, sumas_parciales)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,12), dpi=150)\n",
    "\n",
    "    plt.plot(np.arange(1,101), aportes)\n",
    "    plt.ylim(0,100)\n",
    "    plt.xlim(1,100)\n",
    "    plt.title('Porcentaje de varianza aportado por\\nlas primeras 100 componentes principales', fontsize=22)\n",
    "    plt.xlabel('Alfa', fontsize=22)\n",
    "    plt.ylabel('Porcentaje de aporte', fontsize=22)\n",
    "    ax.tick_params(labelsize=20)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('../imagenes_informe/aporte_autovalores.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploteo del accuracy variando con k=5 y 10000 imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_all_alfas = pd.read_csv(\"../data_mediciones/pred_A1_2_A100_n10000.csv\") #Levantamos el csv que contiene la data reducida a 100 componentes principales\n",
    "all_alfas_array = (df_all_alfas.values)[:,1:].astype('int')\n",
    "print(f\"Cantidad de vecinos distintos probados: {all_alfas_array.shape[1]}\")\n",
    "print(f\"Tamaño del dataset de testing         : {all_alfas_array.shape[0]}\")\n",
    "\n",
    "accuracy_a = [0]\n",
    "for i in range(0, all_alfas_array.shape[1]):\n",
    "    accuracy_a.append(accuracy_score(all_alfas_array[:,i], labels_2000))\n",
    "\n",
    "\n",
    "def plotear_todos_alfa(acc, save=False):\n",
    "    TITLE_SIZE = 24\n",
    "    TICK_SIZE = 22\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(22,14), dpi=150)\n",
    "    plt.plot(np.arange(0, len(acc)), np.array(acc), label='Accuracy')\n",
    "    \n",
    "    plt.title(\"Accuracy por alfa con 8000 imagenes y k=5\", fontsize=24)\n",
    "    plt.xlabel('Alfa', fontsize=TITLE_SIZE)\n",
    "    plt.ylabel('Accuracy', fontsize=TITLE_SIZE)\n",
    "    plt.xlim(0, len(acc)-1)\n",
    "    ax.grid(axis='x', which='both')\n",
    "    plt.xticks(np.arange(0,101,10))\n",
    "    plt.legend(loc=\"best\", fontsize=TITLE_SIZE)\n",
    "    ax.tick_params(labelsize=TICK_SIZE)\n",
    "    \n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_major_formatter(ScalarFormatter())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('../imagenes_informe/accuracy_por_alfa_8000_imagenes.png')\n",
    "    plt.show()\n",
    "    \n",
    "plotear_todos_alfa(accuracy_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis temporal de alfa vs tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def plotear_alfas_vs_tiempo(alfas, tiempos, save=False):\n",
    "    TITLE_SIZE = 24\n",
    "    TICK_SIZE = 22\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(22,14), dpi=150)\n",
    "    plt.plot(np.array(alfas), tiempos, color='orange', label='Tiempo')\n",
    "    \n",
    "    m, b = np.polyfit(np.array(alfas), np.array(tiempos), 1)\n",
    "    print(f\"m: {m}, b: {b}\")\n",
    "    plt.plot(np.array(alfas), m*np.array(alfas) + b, 'b--', label='Aproximación lineal')\n",
    "    \n",
    "    \n",
    "    plt.title(\"Tiempo en entrenar y clasificar para distintos alfas con k=5\", fontsize=24)\n",
    "    plt.xlabel('Alfa', fontsize=TITLE_SIZE)\n",
    "    plt.ylabel('Tiempo de ejecución en segundos', fontsize=TITLE_SIZE)\n",
    "    ax.grid(axis='x', which='both')\n",
    "    plt.xticks(alfas)\n",
    "    plt.legend(loc=\"best\", fontsize=TITLE_SIZE)\n",
    "    ax.tick_params(labelsize=TICK_SIZE)\n",
    "    \n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_major_formatter(ScalarFormatter())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('../imagenes_informe/alfas_vs_tiempo_8000_imagenes_line_predict.png')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploteo del accuracy obtenido con KNN y PCA para distintos alfas y k fijo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def plotear_acc_por_alfa(alfas, accs, k_usado):\n",
    "    x=np.arange(len(alfas))\n",
    "    fig,ax=plt.subplots(figsize=(12,10))\n",
    "    plt.xticks(x,alfas)\n",
    "    plt.xticks(size=12)\n",
    "    plt.yticks(size=12)\n",
    "    plt.ylim(0.0,1.1)\n",
    "    plt.bar(x=x, height=accs, color=colores)\n",
    "    plt.title('Accuracy para distintos alfas con k= {}'.format(k_usado), fontsize=16)\n",
    "    for i in range(len(accs)):\n",
    "        plt.text(x = x[i]-0.3 , y = accs[i]+0.01, s = str(accs[i]), size = 12)\n",
    "    plt.xlabel('Alfa', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmaps de Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%tiempo\n",
    "def plotear_heatmap(data, ks, alfas, K, save=False):\n",
    "    fig, ax = plt.subplots(figsize=(8,6), dpi=150)\n",
    "\n",
    "    sns.set(font_scale=1.25)\n",
    "    ax = sns.heatmap(data, cmap='viridis', vmin=0.93, vmax=0.955)\n",
    "\n",
    "    ax.collections[0].colorbar.set_label(\"Accuracy\", fontsize=20)\n",
    "    ax.set_xlabel('Alfa', fontsize=20)\n",
    "    ax.set_xticklabels(alfas, fontsize=20)\n",
    "    ax.set_yticklabels(ks, fontsize=20)\n",
    "    ax.set_ylabel('k', fontsize=20)\n",
    "    ax.set_title(f'Heatmap con el accuracy promedio de cada\\npareja luego de cross validation con {K} folds')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'../imagenes_informe/heatmap_{K}_folds.png')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def matriz_de_conf(y_val, y_pred):\n",
    "    cm = confusion_matrix(y_val,y_pred, labels=clases)\n",
    "    fig,ax=plt.subplots(figsize=(10,10), dpi=150)\n",
    "\n",
    "\n",
    "    ax=sns.heatmap(cm, cmap='viridis', annot=True,fmt=\"d\")\n",
    "    ax.collections[0].colorbar.set_label(\"Cantidad de datos clasificados\", fontsize=20)\n",
    "    plt.title('Matriz de confusión sobre los datos de validación', fontsize=18)\n",
    "    plt.ylabel('Labels reales', fontsize=16)\n",
    "    plt.xlabel('Labels predichos', fontsize=16)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploteo de los números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_mat_conf = pd.read_csv('../data_mediciones/pred_a19_k3_conf_mat.csv')\n",
    "df_real = pd.read_csv('../data/train.csv')\n",
    "\n",
    "imagen_mat_conf = df_real.values[33600:, 1:]\n",
    "real_mat_conf = df_real.values[33600:,0]\n",
    "pred_mat_conf = df_mat_conf['alfa: 19'].values\n",
    "accuracy_score(real_mat_conf, pred_mat_conf)\n",
    "\n",
    "i_uno_x_cero = []\n",
    "i_cuatro_x_nueve = []\n",
    "i_nueve_x_cuatro = []\n",
    "indice_cero = -1\n",
    "for i in range(real_mat_conf.shape[0]):\n",
    "    if real_mat_conf[i] == 0:\n",
    "        indice_cero = i\n",
    "    if real_mat_conf[i] == 0 and pred_mat_conf[i] == 1:\n",
    "        i_uno_x_cero.append(i)\n",
    "    if real_mat_conf[i] == 4 and pred_mat_conf[i] == 9:\n",
    "        i_nueve_x_cuatro.append(i)\n",
    "    if real_mat_conf[i] == 9 and pred_mat_conf[i] == 4:\n",
    "        i_cuatro_x_nueve.append(i)\n",
    "\n",
    "i_uno_x_cero = i_uno_x_cero[0]\n",
    "\n",
    "def plotear_numero(indice, imagenes):\n",
    "    imagen = imagenes[indice].reshape(28, 28) \n",
    "    fig, ax = plt.subplots(figsize=(5,5), dpi=150)\n",
    "    plt.imshow(imagen, cmap=\"gray_r\")\n",
    "    plt.grid(False) \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 0 ns, total: 12 µs\n",
      "Wall time: 15.5 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_val(data,labels, K, fold):\n",
    "    datos_x_fold= data.shape[0]//K\n",
    "    train= []\n",
    "    labels_train=[]\n",
    "    val=[]\n",
    "    labels_val=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        if i<fold*(datos_x_fold) or i>=(fold+1)*(datos_x_fold):\n",
    "            train.append(data[i])\n",
    "            labels_train.append(labels[i])\n",
    "        else:\n",
    "            val.append(data[i])\n",
    "            labels_val.append(labels[i])\n",
    "    return np.array(train),np.array(labels_train), np.array(val), np.array(labels_val)\n",
    "\n",
    "\n",
    "def cross_val_KNN(set_train,labels_train, set_test,labels_test, ks, K):\n",
    "    mejorK=ks[0]\n",
    "    mejor_prec=-1\n",
    "    precisiones=[]\n",
    "    for k in tqdm(range(len(ks))):\n",
    "    \n",
    "        precision_por_bloque=0\n",
    "        for i in range(K):\n",
    "            X_training, y_training, X_valid, y_valid = train_val(set_train, labels_train, K, i)\n",
    "            cls = metnum.KNNClassifier(ks[k])   \n",
    "            cls.fit(X_training, y_training)\n",
    "            y_pred = cls.predict(X_valid)\n",
    "        \n",
    "\n",
    "            acc = accuracy_score(y_valid, y_pred)\n",
    "            precision_por_bloque+=acc\n",
    "        \n",
    "        prec=precision_por_bloque/K\n",
    "        precisiones.append([prec, ks[k]])\n",
    "        \n",
    "        if mejor_prec==-1 or prec>mejor_prec:\n",
    "                mejor_prec=prec\n",
    "                mejorK=ks[k]\n",
    "           \n",
    "    clf = metnum.KNNClassifier(mejorK)\n",
    "    clf.fit(set_train, y_train)\n",
    "    y_pred = clf.predict(set_test)\n",
    "\n",
    "    acc_final = accuracy_score(labels_test, y_pred)\n",
    "\n",
    "    return [[acc_final,mejorK], precisiones] #Devolvemos acc testing con mejor K y lista de accuracy por k en validacion\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "def cross_val_PCA(set_train,labels_train,ks, alphas,K):\n",
    "    mejorK=ks[0]\n",
    "    mejorA=alphas[0]\n",
    "    n_comp= max(alphas)\n",
    "    mejor_prec=-1\n",
    "    precisiones=np.zeros((len(ks), len(alphas)))\n",
    "    \n",
    "    pca=metnum.PCA(n_comp)\n",
    "    \n",
    "    \n",
    "    for i in range(K):\n",
    "        \n",
    "        X_training, y_training, X_valid, y_valid = train_val(set_train, labels_train, K, i)\n",
    "        pca.fit(X_training)\n",
    "        \n",
    "        \n",
    "\n",
    "        for indexK, k in enumerate(ks):\n",
    "            cls = metnum.KNNClassifier(k)\n",
    "\n",
    "            for indexA, a in enumerate(alphas):\n",
    "                \n",
    "                X_training_PCA=pca.custom_transform(X_training,a)\n",
    "                X_valid_PCA=pca.custom_transform(X_valid,a)\n",
    "                \n",
    "                cls.fit(X_training_PCA, y_training)\n",
    "                y_pred = cls.predict(X_valid_PCA)\n",
    "\n",
    "\n",
    "                acc = accuracy_score(y_valid, y_pred)\n",
    "                precisiones[indexK][indexA]+=acc\n",
    "                print('acc:', acc, '\\n','K: ', k, 'A: ',a)\n",
    "                print('Precisiones:\\n', precisiones)\n",
    "   \n",
    "        \n",
    "    precisiones/=K\n",
    "    \n",
    "    maximos=np.where(precisiones == precisiones.max())\n",
    "    \n",
    "    mejor_prec=precisiones.max()\n",
    "    mejorK=ks[maximos[0][0]]\n",
    "    mejorA=alphas[maximos[1][0]]\n",
    "\n",
    "    return [[mejor_prec,mejorK, mejorA], precisiones]   \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
